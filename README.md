
# ğŸ”¥ Browser LLM Agent â€“ Proof of Concept

This project is a **lightweight demo** showing how a **language model agent** can live entirely in the browser and still handle more than text. The agent can reason in natural language, call external tools like search engines or custom APIs, and even run live JavaScript snippets in a sandbox.

Think of it as a starter kit for experimenting with â€œLLMs that act.â€


---

## âœ¨ Highlights

âœ… **ğŸ› Pick Your Model Provider**  
- Works with AI Pipe Proxy API (default), plus optional OpenAI, Gemini, Claude, and others.
- Simple dropdown to swap between models in real time.  

âœ… **ğŸ”„ Reasoning Loop Agent**  
- Agent keeps looping: analyze â†’ call tool â†’ reflect â†’ continue.
- Uses OpenAI-style function calling to trigger tools cleanly. 

âœ… **ğŸ›  Built-in Tools**  
- ğŸ” Web Search (Google snippets) â€“ grab quick context.
- ğŸ”— AI Pipe Workflows â€“ chain AI processes flexibly.
- âš¡ JavaScript Sandbox â€“ run small JS safely inside the browser.

âœ… **ğŸ¨ Minimal but Usable UI**  
- Bootstrap-based chat interface.
- File uploads supported.
- Errors surface through styled alerts.
- Debug panel with logs + performance markers. 

---

## ğŸ“‹ Why This Project?

Most LLM demos just send a prompt â†’ get an answer. Real agents do more: they think, call tools, and iterate until finished.
This POC is designed to:
1. Show how that loop can run entirely client-side in JS.
2. Stay hackable and minimal so others can build on it.

### Agent Logic (Conceptual)
```python
def loop(llm):
    msg = [user_input()]
    while True:
        output, tool_calls = llm(msg, tools)
        print("Agent: ", output)
        if tool_calls:
            msg += [handle_tool_call(tc) for tc in tool_calls]
        else:
            msg.append(user_input())
````

---

## ğŸš€ Setup & Run

### What Youâ€™ll Need

* A modern browser (Chrome/Edge/Firefox).
* API keys for:

  * [AI Pipe](https://aipipe.org/) proxy API (recommended)
  * Optional: OpenAI, Gemini, or other providers.

### Setup

1. Clone this repo:

   ```bash
   git clone https://github.com/DevyanshJain/TDS-LLM-Agent
   cd TDS-LLM-Agent
   ```

2. Open `index.html` in your browser.
   *(No backend server required â€” everything runs client-side!)*

3. Configure your API key in the **Settings Panel** inside the app.

---

## ğŸ“– Example Conversation

**User:** Interview me to create a blog post.
**Agent:** Sure! Whatâ€™s the post about?

**User:** About IBM.
**Agent:** Let me search for IBM.
â†’ *calls `search("IBM")`*

**Agent:** IBM is a global tech company founded in 1911...

**User:** Next step, please.
**Agent:** Letâ€™s draft an outline for your blog post...

---

## ğŸ§ª Deliverable

* A **browser JS app** with:

  * LLM chat window
  * Google Search snippets
  * AI Pipe proxy integration
  * JS code execution sandbox

* Uses **OpenAI-style function calling**.

* Handles errors gracefully.

* Easy to extend for more tools.

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ index.html   # Frontend UI (chat + settings)
â”œâ”€â”€ agent.js     # Core agent loop, providers, and tools
â”œâ”€â”€ styles.css     # css file
â””â”€â”€ README.md    # Documentation (this file)
```

---

## ğŸ™Œ Acknowledgements

* [AI Pipe](https://aipipe.org/) for proxy API workflows
* OpenAI/Anthropic/Google for LLM providers
* Bootstrap for UI components

---
